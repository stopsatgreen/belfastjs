<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Happy Talk - Belfast JS</title>

		<meta name="description" content="A framework for easily creating beautiful presentations using HTML">
		<meta name="author" content="Hakim El Hattab">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="css/reveal.min.css">
		<link rel="stylesheet" href="css/theme/custom.css" id="theme">

		<!-- For syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- If the query includes 'print-pdf', include the PDF print sheet -->
		<script>
			if( window.location.search.match( /print-pdf/gi ) ) {
				var link = document.createElement( 'link' );
				link.rel = 'stylesheet';
				link.type = 'text/css';
				link.href = 'css/print/pdf.css';
				document.getElementsByTagName( 'head' )[0].appendChild( link );
			}
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">

				<section>
					<h1>Happy Talk</h1>
					<h2>BelfastJS, 10/12/14</h2>
				</section>

				<section>
					<h2>Peter Gasston</h2>
					<h2>@stopsatgreen</h2>
					<h2>broken-links.com</h2>
				</section>

				<section>
					<h2>(Movie montage)</h2>
					<ol>
						<li>Star Trek</li>
						<li>Star Trek Scotty Mouse (barrier)</li>
						<li>Her Samantha (synthesis)</li>
						<li>Moon (recognition)</li>
						<li>2001 (cognition)</li>
					</ol>

					<aside class="notes">
						We are born to talk. Typing is a barrier to communication. Moviemakers know this.
					</aside>
				</section>

				<section>
					<h1>55% of teens</h1>
					<h1>41% of adults</h1>
					<h3>use voice search every day*</h3>
					<h4>*maybe</h4>

					<aside class="notes">
						From Google research, but sources not provided. Could be ‘of teens who use, 55% use every day’. http://googleblog.blogspot.co.uk/2014/10/omg-mobile-voice-survey-reveals-teens.html
					</aside>
				</section>

				<section data-background="images/amazon.echo.jpg" data-background-size="contain">
					<h2>Amazon : ‘Alexa’</h2>
					<h2>Apple : Siri</h2>
					<h2>Google : Voice Search</h2>
					<h2>Microsoft : Cortana</h2>

					<aside class="notes">
						Google clear winner according to https://www.stonetemple.com/great-knowledge-box-showdown/
					</aside>
				</section>

				<section data-background="images/crowdedstreet.jpg" data-background-size="cover">
					<h1>10% of Baidu</h1>
					<h3>search queries are by voice</h3>
					<h2 class="fragment">That’s ~500m per day</h2>

					<aside class="notes">
						Character input is hard, plus high rural illiteracy. http://blogs.wsj.com/digits/2014/11/21/baidus-andrew-ng-on-deep-learning-and-innovation-in-silicon-valley/
						http://iaminchina.wordpress.com/2010/04/13/crowded-street-in-xian/
					</aside>
				</section>

				<section>
					<h1>Synthesis</h1>

					<aside class="notes">
						Long history of replicating voice with sound (Brazen Heads back to ~12th C.) but first systems emerged in 1960s. Bell Labs 1961 sang Daisy Bell, coincidentally Arthur C. Clarke was visiting. Today Stephen Hawking uses system with old voice as it’s ‘his’.
					</aside>
				</section>

				<section id="synthesis1">
					<h2>Chrome/Safari</h2>
					<pre><code data-trim>
var txt = 'Hello world',
	say = new SpeechSynthesisUtterance(txt);
window.speechSynthesis.speak(say);
					</code></pre>

					<button class="big">Play</button>
				</section>

				<section id="synthesis2">
					<h3>SpeechSynthesisUtterance Attributes</h3>
					<pre><code data-trim contenteditable>
var txt = 'Hello world',
	say = new SpeechSynthesisUtterance(txt);
	say.lang = 'en-GB';
	say.pitch = 0.75;
	say.rate = 1.5;
	say.volume = 0.5;
window.speechSynthesis.speak(say);
					</code></pre>

					<button class="big">Play</button>
				</section>

				<section id="synthesis3">
					<h3>SpeechSynthesis Methods</h3>
					<pre><code data-trim contenteditable>
var txt = 'Hello world',
	say = new SpeechSynthesisUtterance(txt);
window.speechSynthesis.speak(say);
window.speechSynthesis.pause(say);
window.speechSynthesis.resume(say);
window.speechSynthesis.cancel(say);
					</code></pre>

					<button class="big">Play</button>
				</section>

				<section>
					<h3>SpeechSynthesis Attributes</h3>
					<pre><code data-trim contenteditable>
var txt = 'Hello world',
	say = new SpeechSynthesisUtterance(txt),
	speak = window.speechSynthesis.speak(say);
if (speak.pending) {}
if (speak.speaking) {}
if (speak.paused) {}
					</code></pre>
				</section>

				<section id="synthesis4">
					<h3>SpeechSynthesisUtterance Events</h3>
					<pre><code data-trim contenteditable>
var txt = 'Hello world',
	say = new SpeechSynthesisUtterance(txt);
	say.onstart = function () {};
	say.onpause = function () {};
	say.onresume = function () {};
	say.oncancel = function () {};
	say.onerror = function () {};
	say.onend = function () {};
window.speechSynthesis.speak(say);
					</code></pre>

					<button class="big">Play</button>
					<output></output>
				</section>

				<section>
					<h2>As a service</h2>
					<ol>
						<li>http://developer.att.com/apis/speech</li>
						<li>https://ws.neospeech.com/</li>
						<li>https://www.cereproc.com/en/products/cloud</li>
						<li>http://www.ivona.com/en/for-business/speech-cloud/</li>
					</ol>
				</section>

				<section>
					<h2>Neospeech</h2>
				<pre>https://tts.neospeech.com/rest_1_1.php?method=<mark>ConvertSimple</mark>&email=mail@example.com&accountId=abcd1234&loginKey=LoginKey&loginPassword=123abc45de&voice=TTS_PAUL_DB&outputFormat=FORMAT_WAV&sampleRate=16&text=<mark>Hello+Belfast+JS</mark></pre>

					<pre class="fragment"><code data-trim class="break-word">
&lt;response conversionNumber="28" resultCode="0" resultString="success" status="Queued" statusCode="1"/&gt;
					</code></pre>

				<pre class="fragment">https://tts.neospeech.com/rest_1_1.php?method=<mark>GetConversionStatus</mark>&email=mail@example.com&accountId=abcd1234&<mark>conversionNumber=28</mark></pre>

					<pre class="fragment"><code data-trim class="break-word">
&lt;response statusCode="1" downloadUrl="https://tts.neospeech.com/audio/a.php/23841309/d44caf624653/result_26.wav" resultCode="0" resultString="success" status="Queued"/&gt;
					</code></pre>
				</section>

				<section>
					<h2>SSML</h2>

					<pre><code data-trim contenteditable>
&lt;speak version="1.0" etc&gt;
	&lt;p&gt;
		&lt;s&gt;Hello Belfast.&lt;/s&gt;
		&lt;s&gt;This is &lt;prosody rate="-20%"&gt;SSML&lt;/prosody&gt;.							&lt;/s&gt;
	&lt;/p&gt;
&lt;/speak&gt;
					</code></pre>
				</section>

				<section>
					<h1>Recognition</h1>

					<aside class="notes">
						Developed by Bell in 1952. Could recognise numbers spoken by one person. [Get screengrab / find picture]. 1970s Carnegie Mellon HARPY could recognise 1,000 words. 1980s Hidden Markov method [Teddy Ruxpin]. Chops waves into phonemes and attempts to form words.
					</aside>
				</section>

				<section data-background="images/startrek.jpg" data-background-size="cover">
					<h2>Challenges</h2>
					<ol>
						<li>Accents (Scottish + Siri)</li>
						<li>Multiple users</li>
						<li>Multiple languages</li>
					</ol>
				</section>

				<section>
					<h2>Web Speech API</h2>
					<pre><code data-trim contenteditable>
var recog = new SpeechRecognition();
					</code></pre>

					<h2 class="fragment">x-browser</h2>
					<pre class="fragment"><code data-trim contenteditable>
var speechRecognition = (
	window.SpeechRecognition ||
	window.webkitSpeechRecognition
);
var recog = new speechRecognition();
					</code></pre>
				</section>

				<section>
					<h3>SpeechRecognition Methods</h3>
					<pre><code data-trim contenteditable>
var recog = new SpeechRecognition();
recog.start();
recog.stop();
recog.abort();
					</code></pre>
				</section>

				<section>
					<h3>SpeechRecognition Events</h3>
					<pre><code data-trim contenteditable>
var recog = new SpeechRecognition();
recog.onresult = function () {};
recog.onnomatch = function () {};
recog.onerror = function () {};
					</code></pre>

					<aside class="notes">
						SpeechRecognitionError interface for reporting errors.
					</aside>
				</section>

				<section id="recognition1">
					<h2><abbr title="Minimum Viable Script">MVS</abbr></h2>
					<pre><code data-trim contenteditable>
var recog = new SpeechRecognition();
recog.onresult = function (result) {
	output.textContent = results[0][0].transcript;
};
btn.onclick = recog.start();
					</code></pre>

					<button class="big">Start</button>
					<output></output>

					<aside class="notes">
						SpeechRecognitionEvent, results list
					</aside>
				</section>

				<section id="recognition2">
					<h3>SpeechRecognition Events</h3>
					<ol>
						<li class="fragment">start</li>
						<li class="fragment">audiostart</li>
						<li class="fragment">soundstart</li>
						<li class="fragment">speechstart</li>
						<li class="fragment">speechend</li>
						<li class="fragment">soundend</li>
						<li class="fragment">audioend</li>
						<li class="fragment">end</li>
					</ol>

					<button class="big">Start</button>
				</section>

				<section>
					<h2>Interim Results</h2>
					<pre><code data-trim>
var recog = new SpeechRecognition();
recog.interimResults = true;
recog.onresult = function (result) {
  var thisResult = result.results[0],
	transcript = thisResult[0].transcript;
  if (thisResult.isFinal) {
	finalOutput.textContent = transcript;
  } else {
	interimOutput.textContent = transcript;
  }
};
btn.onclick = recog.start();
					</code></pre>
				</section>

				<section>
					<h2>Continuous</h2>
					<pre><code data-trim>
var recog = new SpeechRecognition();
recog.continuous = true;
recog.interimResults = true;
recog.onresult = function (result) {
	console.log(result.results[0][0].transcript);
};
btn.onclick = function () {
  if (listening) {
	recog.stop();
  } else {
	recog.start();
  }
}
					</code></pre>
				</section>

				<section>
					<h2>SpeechRTC +</h2>
					<h2>Web Speech API</h2>

					<aside class="notes">
						Node online, Web Workers offline. https://wiki.mozilla.org/SpeechRTC_-_Speech_enabling_the_open_web
					</aside>
				</section>

				<section>
					<h2>(Picard demo)</h2>

					<aside class="notes">
						Basically just matching a string / regex
					</aside>
				</section>

				<section data-background="images/wit.ai.png" data-background-size="contain"></section>

				<section data-background="images/wit-dashboard.png" data-background-size="contain"></section>

				<section>
					<h2>Wit.ai</h2>
					<ol>
						<li>With Speech Recognition + text</li>
						<li>With Microphone.js</li>
						<li>With direct speech (Node + Web Audio API)</li>
					</ol>

					<aside class="notes">
						2. Opinionated. Gives you a handful of methods & events, no fine control. http://localhost/~petergasston/prototypes/mucking-about/wit/
						3. http://blog.groupbuddies.com/posts/39-tutorial-html-audio-capture-streaming-to-node-js-no-browser-extensions
					</aside>
				</section>

				<section data-background="images/api.ai.png" data-background-size="contain"></section>

				<section>
					<h2>JuliusJS</h2>

					<pre><code data-trim>
var recog = new Julius();
recog.onrecognition = function (result) {
	console.log(result);
}
					</code></pre>
				</section>

				<section>
					<h1>Cognition</h1>
				</section>

				<section>
					<h1>The End</h1>
				</section>

			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.min.js"></script>
		<script>

			// Full list of configuration options available here:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
				transition: Reveal.getQueryHash().transition || 'linear', // default/cube/page/concave/zoom/linear/fade/none

				// Parallax scrolling
				// parallaxBackgroundImage: 'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg',
				// parallaxBackgroundSize: '2100px 900px',

				// Optional libraries used to extend on reveal.js
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
					{ src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
				]
			});

		</script>
		<script src="js/custom.js"></script>
	</body>
</html>
