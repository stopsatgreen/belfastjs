<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>reveal.js - The HTML Presentation Framework</title>

		<meta name="description" content="A framework for easily creating beautiful presentations using HTML">
		<meta name="author" content="Hakim El Hattab">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="css/reveal.min.css">
		<link rel="stylesheet" href="css/theme/custom.css" id="theme">

		<!-- For syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- If the query includes 'print-pdf', include the PDF print sheet -->
		<script>
			if( window.location.search.match( /print-pdf/gi ) ) {
				var link = document.createElement( 'link' );
				link.rel = 'stylesheet';
				link.type = 'text/css';
				link.href = 'css/print/pdf.css';
				document.getElementsByTagName( 'head' )[0].appendChild( link );
			}
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">

				<section>
					<h1>Happy Talk</h1>
					<h2>BelfastJS, 10/12/14</h2>
				</section>

				<section>
					<h2>Peter Gasston</h2>
					<h2>@stopsatgreen</h2>
					<h2>broken-links.com</h2>
				</section>

				<section>
					<h2>(Movie montage)</h2>
					<h2>(Hodor?)</h2>

					<aside class="notes">
						We are born to talk. Typing is a barrier to communication. Moviemakers know this.
					</aside>
				</section>

				<section>
					<h1>55% of teens</h1>
					<h1>41% of adults</h1>
					<h3>use voice search every day</h3>
					<h4>(maybe)</h4>

					<aside class="notes">
						From Google research, but sources not provided. Could be ‘of teens who use, 55% use every day’. http://googleblog.blogspot.co.uk/2014/10/omg-mobile-voice-survey-reveals-teens.html
					</aside>
				</section>

				<section>
					<h2>‘Alexa’, Cortana, Google, Siri</h2>

					<aside class="notes">
						https://www.stonetemple.com/great-knowledge-box-showdown/
					</aside>
				</section>

				<section data-background="images/crowdedstreet.jpg" data-background-size="cover">
					<h1>10% of Baidu</h1>
					<h3>search queries are by voice</h3>
					<h2 class="fragment">That’s ~500m per day</h2>

					<aside class="notes">
						Character input is hard, plus high rural illiteracy. http://blogs.wsj.com/digits/2014/11/21/baidus-andrew-ng-on-deep-learning-and-innovation-in-silicon-valley/
						http://iaminchina.wordpress.com/2010/04/13/crowded-street-in-xian/
					</aside>
				</section>

				<section>
					<h1>Synthesis</h1>
				</section>

				<section>
					<h2>Chrome/Safari</h2>
					<pre><code data-trim contenteditable>
var txt = 'Hello world',
	say = new SpeechSynthesisUtterance(txt);
window.speechSynthesis.speak(say);
					</code></pre>
				</section>

				<section>
					<h3>SpeechSynthesisUtterance Attributes</h3>
					<pre><code data-trim contenteditable>
var txt = 'Hello world',
	say = new SpeechSynthesisUtterance(txt);
	say.lang = 'en-GB';
	say.pitch = 0.75;
	say.rate = 1.5;
	say.volume = 0.5;
window.speechSynthesis.speak(say);
					</code></pre>
				</section>

				<section>
					<h3>SpeechSynthesis Methods</h3>
					<pre><code data-trim contenteditable>
var txt = 'Hello world',
	say = new SpeechSynthesisUtterance(txt);
window.speechSynthesis.speak(say);
window.speechSynthesis.pause(say);
window.speechSynthesis.resume(say);
window.speechSynthesis.cancel(say);
					</code></pre>
				</section>

				<section>
					<h3>SpeechSynthesisUtterance Events</h3>
					<pre><code data-trim contenteditable>
var txt = 'Hello world',
	say = new SpeechSynthesisUtterance(txt);
	say.onstart = function () {};
	say.onpause = function () {};
	say.onresume = function () {};
	say.oncancel = function () {};
	say.onerror = function () {};
	say.onend = function () {};
window.speechSynthesis.speak(say);
					</code></pre>
				</section>

				<section>
					<h3>SpeechSynthesis Attributes</h3>
					<pre><code data-trim contenteditable>
var txt = 'Hello world',
	say = new SpeechSynthesisUtterance(txt),
	speak = window.speechSynthesis.speak(say);
if (speak.pending) {}
if (speak.speaking) {}
if (speak.paused) {}
					</code></pre>
				</section>

				<section>
					<h2>As a service</h2>
					<ol>
						<li>http://developer.att.com/apis/speech</li>
						<li>https://ws.neospeech.com/</li>
						<li>https://www.cereproc.com/en/products/cloud</li>
						<li>http://www.ivona.com/en/for-business/speech-cloud/</li>
					</ol>
				</section>

				<section>
					<h2>Neospeech</h2>
				<pre>https://tts.neospeech.com/rest_1_1.php?method=ConvertSimple&email=mail@example.com&accountId=abcd1234&loginKey=LoginKey&loginPassword=123abc45de&voice=TTS_PAUL_DB&outputFormat=FORMAT_WAV&sampleRate=16&text=Hello+London+JS</pre>

					<pre><code data-trim contenteditable>
&lt;response resultCode="0" resultString="success" conversionNumber="28" status="Queued" statusCode="1"/&gt;
					</code></pre>

				<pre>https://tts.neospeech.com/rest_1_1.php?method=GetConversionStatus&email=mail@example.com&accountId=abcd1234&conversionNumber=28</pre>

					<pre><code data-trim contenteditable>
&lt;response resultCode="0" resultString="success" status="Queued" statusCode="1" downloadUrl="https://tts.neospeech.com/audio/a.php/23841309/d44caf624653/result_26.wav" /&gt;
					</code></pre>
				</section>

				<section>
					<h2>SSML</h2>

					<pre><code data-trim contenteditable>
&lt;speak version="1.0" etc&gt;
	&lt;p&gt;
		&lt;s&gt;Hello Belfast.&lt;/s&gt;
		&lt;s&gt;This is &lt;prosody rate="-20%"&gt;SSML&lt;/prosody&gt;.							&lt;/s&gt;
	&lt;/p&gt;
&lt;/speak&gt;
					</code></pre>
				</section>

				<section>
					<h1>Recognition</h1>
				</section>

				<section>
					<h2>Challenges</h2>
					<ol>
						<li>Accents (Scottish + Siri)</li>
						<li>Multiple users</li>
						<li>Multiple languages</li>
					</ol>
				</section>

				<section>
					<h2>Web Speech API</h2>
					<pre><code data-trim contenteditable>
var recog = new SpeechRecognition();
					</code></pre>

					<h2 class="fragment">x-browser</h2>
					<pre class="fragment"><code data-trim contenteditable>
var speechRecognition = (
	window.SpeechRecognition ||
	window.webkitSpeechRecognition
);
var recog = new speechRecognition();
					</code></pre>
				</section>

				<section>
					<h3>SpeechRecognition Methods</h3>
					<pre><code data-trim contenteditable>
var recog = new SpeechRecognition();
recog.start();
recog.stop();
recog.abort();
					</code></pre>
				</section>

				<section>
					<h3>SpeechRecognition Events</h3>
					<pre><code data-trim contenteditable>
var recog = new SpeechRecognition();
recog.onstart = function () {};
recog.onaudiostart = function () {};
recog.onsoundstart = function () {};
recog.onspeechstart = function () {};
recog.onspeechend = function () {};
recog.onsoundend = function () {};
recog.onaudioend = function () {};
recog.onend = function () {};
					</code></pre>
				</section>

				<section>
					<h3>SpeechRecognition Events</h3>
					<pre><code data-trim contenteditable>
var recog = new SpeechRecognition();
recog.onresult = function () {};
recog.onnomatch = function () {};
recog.onerror = function () {};
					</code></pre>

					<aside class="notes">
						SpeechRecognitionError interface for reporting errors.
					</aside>
				</section>

				<section>
					<h2><abbr title="Minimum Viable Script">MVS</abbr></h2>
					<pre><code data-trim contenteditable>
var recog = new SpeechRecognition();
recog.onresult = function (result) {
	console.log( results[0][0].transcript );
};
btn.onclick = recog.start();
					</code></pre>

					<aside class="notes">
						SpeechRecognitionEvent, results list
					</aside>
				</section>

				<section>
					<h2>Interim Results</h2>
					<pre><code data-trim>
var recog = new SpeechRecognition();
recog.interimResults = true;
recog.onresult = function (result) {
	var thisResult = result.results[0],
		transcript = thisResult[0].transcript;
	if (thisResult.isFinal) {
		console.log('final', transcript);
	} else {
		console.log('interim', transcript);
	}
};
btn.onclick = recog.start();
					</code></pre>
				</section>

				<section>
					<h2>Continuous</h2>
					<pre><code data-trim>
var recog = new SpeechRecognition();
recog.continuous = true;
recog.interimResults = true;
recog.onresult = function (result) {
	console.log( result.results[0][0].transcript );
};
btn.onclick = function () {
  if (listening) {
	recog.stop();
  } else {
	 recog.start();
  }
}
					</code></pre>
				</section>

				<section>
					<h2>SpeechRTC +</h2>
					<h2>Web Speech API</h2>

					<aside class="notes">
						Node online, Web Workers offline. https://wiki.mozilla.org/SpeechRTC_-_Speech_enabling_the_open_web
					</aside>
				</section>

				<section>
					<h2>(Picard demo)</h2>

					<aside class="notes">
						Basically just matching a string / regex
					</aside>
				</section>

				<section data-background="images/wit.ai.png" data-background-size="contain"></section>

				<section data-background="images/wit-dashboard.png" data-background-size="contain"></section>

				<section>
					<h2>Wit.ai</h2>
					<ol>
						<li>With Speech Recognition + text</li>
						<li>With Microphone.js</li>
						<li>With direct speech (Node + Web Audio API)</li>
					</ol>

					<aside class="notes">	http://blog.groupbuddies.com/posts/39-tutorial-html-audio-capture-streaming-to-node-js-no-browser-extensions
					</aside>
				</section>

				<section data-background="images/api.ai.png" data-background-size="contain"></section>

				<section>
					<h2>JuliusJS</h2>

					<pre><code data-trim>
var recog = new Julius();
recog.onrecognition = function (result) {
	console.log(result);
}
					</code></pre>
				</section>

				<section>
					<h1>Cognition</h1>
				</section>

				<section>
					<h1>The End</h1>
				</section>

			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.min.js"></script>

		<script>

			// Full list of configuration options available here:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
				transition: Reveal.getQueryHash().transition || 'linear', // default/cube/page/concave/zoom/linear/fade/none

				// Parallax scrolling
				// parallaxBackgroundImage: 'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg',
				// parallaxBackgroundSize: '2100px 900px',

				// Optional libraries used to extend on reveal.js
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
					{ src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
				]
			});

		</script>

	</body>
</html>
